"""
Aetheria ä¸€è‡´æ€§æ¸¬è©¦è…³æœ¬

ç›®æ¨™ï¼šæ¸¬è©¦ Gemini 3 Pro å°åŒä¸€å‡ºç”Ÿè³‡æ–™é‡è¤‡æ’ç›¤çš„ä¸€è‡´æ€§
æ–¹æ³•ï¼šå‘¼å« API 10 æ¬¡ï¼Œæ¯”å°çµæœèˆ‡åŸºæº–ç­”æ¡ˆçš„ç›¸ä¼¼åº¦

åŸºæº–ç­”æ¡ˆï¼ˆä¾†è‡ªæ‚¨ä¹‹å‰çš„ Gemini 3 Pro å°è©±ï¼‰ï¼š
- å‘½å®®ï¼šå¤ªé™°ï¼ˆæˆŒå®®ï¼‰
- æ ¼å±€ï¼šæ—¥æœˆä¸¦æ˜ã€æ©ŸæœˆåŒæ¢
- å®˜ç¥¿å®®ï¼šå¤©æ¢åŒ–ç§‘ï¼ˆå¯…å®®ï¼‰
- è²¡å¸›å®®ï¼šå¤©æ©Ÿï¼ˆåˆå®®ï¼‰
- å¤«å¦»å®®ï¼šæ­¦æ›²åŒ–ç¥¿+å¤©ç›¸ï¼ˆç”³å®®ï¼‰
- æ€§æ ¼ï¼šæ–¯æ–‡ã€ç´°è†©ã€æº«å’Œã€æœ‰æ¢ç†
"""

import os
import json
import re
from datetime import datetime
from dotenv import load_dotenv
import google.generativeai as genai

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))

# ============================================
# åŸºæº–ç­”æ¡ˆï¼ˆæ‚¨ä¹‹å‰çš„æ­£ç¢º Gemini å°è©±ï¼‰
# ============================================

GROUND_TRUTH = {
    "å‘½å®®": {
        "å®®ä½": "æˆŒ",
        "ä¸»æ˜Ÿ": ["å¤ªé™°"],
        "keywords": ["å¤ªé™°", "æˆŒå®®", "æˆŒ"]
    },
    "æ ¼å±€": {
        "åç¨±": ["æ—¥æœˆä¸¦æ˜", "æ©ŸæœˆåŒæ¢"],
        "keywords": ["æ—¥æœˆä¸¦æ˜", "æ©ŸæœˆåŒæ¢", "æ—¥æœˆ", "æ©Ÿæ¢"]
    },
    "å®˜ç¥¿å®®": {
        "å®®ä½": "å¯…",
        "ä¸»æ˜Ÿ": ["å¤©æ¢"],
        "å››åŒ–": "åŒ–ç§‘",
        "keywords": ["å¤©æ¢", "åŒ–ç§‘", "å¯…å®®", "å®˜ç¥¿"]
    },
    "è²¡å¸›å®®": {
        "å®®ä½": "åˆ",
        "ä¸»æ˜Ÿ": ["å¤©æ©Ÿ"],
        "keywords": ["å¤©æ©Ÿ", "åˆå®®", "è²¡å¸›"]
    },
    "å¤«å¦»å®®": {
        "å®®ä½": "ç”³",
        "ä¸»æ˜Ÿ": ["æ­¦æ›²", "å¤©ç›¸"],
        "å››åŒ–": "åŒ–ç¥¿",
        "keywords": ["æ­¦æ›²", "åŒ–ç¥¿", "å¤©ç›¸", "ç”³å®®", "å¤«å¦»"]
    },
    "æ€§æ ¼ç‰¹è³ª": {
        "keywords": ["æ–¯æ–‡", "ç´°è†©", "æº«å’Œ", "æœ‰æ¢ç†", "æ›¸å·", "æ–‡æ˜Œ", "å¤ªé™°"]
    },
    "éŒ¯èª¤æŒ‡æ¨™": {
        "å‘½å®®çµ•ä¸æ˜¯": ["ç ´è»", "ç”³å®®", "æ®ºç ´ç‹¼"],
        "æ ¼å±€çµ•ä¸æ˜¯": ["æ®ºç ´ç‹¼"],
        "æ€§æ ¼çµ•ä¸æ˜¯": ["ç ´å£", "è¡å‹•", "è®Šè‰²é¾", "ä¸å®‰"]
    }
}

# ============================================
# æ¸¬è©¦åƒæ•¸
# ============================================

BIRTH_INFO = {
    'date': 'è¾²æ›†68å¹´9æœˆ23æ—¥',
    'time': '23:58',
    'location': 'å°ç£å½°åŒ–å¸‚',
    'gender': 'ç”·'
}

TEST_ITERATIONS = 10  # æ¸¬è©¦æ¬¡æ•¸
MODEL_NAME = 'gemini-3-pro-preview'
TEMPERATURE = 0.4  # èˆ‡æ­£å¼æ¸¬è©¦ç›¸åŒ

# ============================================
# æç¤ºè©ï¼ˆç°¡åŒ–ç‰ˆï¼Œå°ˆæ³¨æ–¼å‘½ç›¤çµæ§‹ï¼‰
# ============================================

SYSTEM_INSTRUCTION = """
ä½ æ˜¯ Aetheriaï¼Œç²¾é€šç´«å¾®æ–—æ•¸çš„ AI å‘½ç†é¡§å•ã€‚

é‡è¦åŸå‰‡ï¼š
1. æº–ç¢ºæ€§æœ€é‡è¦ï¼Œä¸å¯ç·¨é€ æ˜Ÿæ›œ
2. æ™šå­æ™‚ï¼ˆ23:00-01:00ï¼‰çš„åˆ¤å®šé‚è¼¯è¦æ˜ç¢ºèªªæ˜
3. å¿…é ˆæ˜ç¢ºèªªå‡ºå‘½å®®ä½ç½®ã€ä¸»æ˜Ÿã€æ ¼å±€

è¼¸å‡ºé¢¨æ ¼ï¼šçµæ§‹æ¸…æ™°ï¼Œå…ˆèªªå‘½ç›¤çµæ§‹ï¼Œå†èªªæ€§æ ¼ã€‚
"""

USER_PROMPT_TEMPLATE = """
è«‹ç‚ºä»¥ä¸‹ç”¨æˆ¶æä¾›ç´«å¾®æ–—æ•¸å‘½ç›¤åˆ†æï¼ˆå°ˆæ³¨æ–¼å‘½ç›¤çµæ§‹ï¼‰ï¼š

å‡ºç”Ÿæ—¥æœŸï¼š{date}
å‡ºç”Ÿæ™‚é–“ï¼š{time}
å‡ºç”Ÿåœ°é»ï¼š{location}
æ€§åˆ¥ï¼š{gender}

è«‹æŒ‰ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼ˆç´„800å­—ï¼‰ï¼š

### ä¸€ã€å‘½ç›¤åŸºç¤çµæ§‹
1. **æ™‚è¾°åˆ¤å®š**ï¼šèªªæ˜ 23:58 å¦‚ä½•è™•ç†ï¼ˆæ™šå­æ™‚ç®—ç•¶æ—¥æˆ–éš”æ—¥ï¼‰
2. **å‘½å®®**ï¼šä½æ–¼å“ªå€‹å®®ä½ï¼Ÿä¸»æ˜Ÿæ˜¯ä»€éº¼ï¼Ÿ
3. **æ ¸å¿ƒæ ¼å±€**ï¼šå±¬æ–¼ä»€éº¼æ ¼å±€ï¼Ÿï¼ˆå¦‚æ—¥æœˆä¸¦æ˜ã€æ®ºç ´ç‹¼ç­‰ï¼‰
4. **é—œéµå®®ä½**ï¼š
   - å®˜ç¥¿å®®ï¼ˆäº‹æ¥­ï¼‰ï¼šå®®ä½ã€ä¸»æ˜Ÿã€å››åŒ–
   - è²¡å¸›å®®ï¼ˆè²¡é‹ï¼‰ï¼šå®®ä½ã€ä¸»æ˜Ÿ
   - å¤«å¦»å®®ï¼ˆæ„Ÿæƒ…ï¼‰ï¼šå®®ä½ã€ä¸»æ˜Ÿã€å››åŒ–

### äºŒã€æ€§æ ¼ç‰¹è³ªï¼ˆ200å­—ï¼‰
ç”¨æ—¥å¸¸èªè¨€æè¿°ï¼Œæ ¸å¿ƒé—œéµè©è‡³å°‘5å€‹ã€‚

**æ³¨æ„**ï¼šå¿…é ˆæ˜ç¢ºèªªå‡ºå®®ä½ï¼ˆå¦‚ã€ŒæˆŒå®®ã€ã€Œç”³å®®ã€ï¼‰ï¼Œä¸å¯æ¨¡ç³Šå¸¶éã€‚
"""

# ============================================
# åˆ†æå‡½å¼
# ============================================

def extract_chart_structure(response_text):
    """
    å¾ LLM å›æ‡‰ä¸­æå–å‘½ç›¤çµæ§‹
    ä½¿ç”¨é—œéµè©åŒ¹é…
    """
    
    result = {
        "raw_text": response_text[:500],  # å‰500å­—ç”¨æ–¼é™¤éŒ¯
        "å‘½å®®": {"found": False, "content": ""},
        "æ ¼å±€": {"found": False, "content": ""},
        "å®˜ç¥¿å®®": {"found": False, "content": ""},
        "è²¡å¸›å®®": {"found": False, "content": ""},
        "å¤«å¦»å®®": {"found": False, "content": ""},
        "æ€§æ ¼": {"found": False, "content": ""},
        "éŒ¯èª¤æŒ‡æ¨™": []
    }
    
    text_lower = response_text.lower()
    
    # æª¢æŸ¥éŒ¯èª¤æŒ‡æ¨™
    for wrong_keyword in GROUND_TRUTH["éŒ¯èª¤æŒ‡æ¨™"]["å‘½å®®çµ•ä¸æ˜¯"]:
        if wrong_keyword in response_text:
            result["éŒ¯èª¤æŒ‡æ¨™"].append(f"å‘½å®®éŒ¯èª¤ï¼šæåˆ°äº†ã€Œ{wrong_keyword}ã€")
    
    for wrong_keyword in GROUND_TRUTH["éŒ¯èª¤æŒ‡æ¨™"]["æ ¼å±€çµ•ä¸æ˜¯"]:
        if wrong_keyword in response_text:
            result["éŒ¯èª¤æŒ‡æ¨™"].append(f"æ ¼å±€éŒ¯èª¤ï¼šæåˆ°äº†ã€Œ{wrong_keyword}ã€")
    
    # æå–å‘½å®®
    for keyword in GROUND_TRUTH["å‘½å®®"]["keywords"]:
        if keyword in response_text:
            result["å‘½å®®"]["found"] = True
            result["å‘½å®®"]["content"] += keyword + " "
    
    # æå–æ ¼å±€
    for keyword in GROUND_TRUTH["æ ¼å±€"]["keywords"]:
        if keyword in response_text:
            result["æ ¼å±€"]["found"] = True
            result["æ ¼å±€"]["content"] += keyword + " "
    
    # æå–å®˜ç¥¿å®®
    for keyword in GROUND_TRUTH["å®˜ç¥¿å®®"]["keywords"]:
        if keyword in response_text:
            result["å®˜ç¥¿å®®"]["found"] = True
            result["å®˜ç¥¿å®®"]["content"] += keyword + " "
    
    # æå–è²¡å¸›å®®
    for keyword in GROUND_TRUTH["è²¡å¸›å®®"]["keywords"]:
        if keyword in response_text:
            result["è²¡å¸›å®®"]["found"] = True
            result["è²¡å¸›å®®"]["content"] += keyword + " "
    
    # æå–å¤«å¦»å®®
    for keyword in GROUND_TRUTH["å¤«å¦»å®®"]["keywords"]:
        if keyword in response_text:
            result["å¤«å¦»å®®"]["found"] = True
            result["å¤«å¦»å®®"]["content"] += keyword + " "
    
    # æå–æ€§æ ¼é—œéµè©
    for keyword in GROUND_TRUTH["æ€§æ ¼ç‰¹è³ª"]["keywords"]:
        if keyword in response_text:
            result["æ€§æ ¼"]["found"] = True
            result["æ€§æ ¼"]["content"] += keyword + " "
    
    return result

def calculate_accuracy(extracted):
    """
    è¨ˆç®—æº–ç¢ºåº¦åˆ†æ•¸
    """
    
    scores = {
        "å‘½å®®": 0,
        "æ ¼å±€": 0,
        "å®˜ç¥¿å®®": 0,
        "è²¡å¸›å®®": 0,
        "å¤«å¦»å®®": 0,
        "æ€§æ ¼": 0,
        "éŒ¯èª¤æ‰£åˆ†": 0
    }
    
    # å‘½å®®ï¼ˆæœ€é‡è¦ï¼Œ40åˆ†ï¼‰
    if extracted["å‘½å®®"]["found"] and "å¤ªé™°" in extracted["å‘½å®®"]["content"]:
        if "æˆŒ" in extracted["å‘½å®®"]["content"]:
            scores["å‘½å®®"] = 40  # å®Œå…¨æ­£ç¢º
        else:
            scores["å‘½å®®"] = 20  # æ˜Ÿå°ä½†å®®ä½ä¸æ˜ç¢º
    
    # æ ¼å±€ï¼ˆ20åˆ†ï¼‰
    if extracted["æ ¼å±€"]["found"]:
        if "æ—¥æœˆä¸¦æ˜" in extracted["æ ¼å±€"]["content"] or "æ©ŸæœˆåŒæ¢" in extracted["æ ¼å±€"]["content"]:
            scores["æ ¼å±€"] = 20
        else:
            scores["æ ¼å±€"] = 5  # æœ‰æåˆ°æ ¼å±€ä½†ä¸å°
    
    # å®˜ç¥¿å®®ï¼ˆ15åˆ†ï¼‰
    if extracted["å®˜ç¥¿å®®"]["found"] and "å¤©æ¢" in extracted["å®˜ç¥¿å®®"]["content"]:
        if "åŒ–ç§‘" in extracted["å®˜ç¥¿å®®"]["content"]:
            scores["å®˜ç¥¿å®®"] = 15
        else:
            scores["å®˜ç¥¿å®®"] = 8
    
    # è²¡å¸›å®®ï¼ˆ10åˆ†ï¼‰
    if extracted["è²¡å¸›å®®"]["found"] and "å¤©æ©Ÿ" in extracted["è²¡å¸›å®®"]["content"]:
        scores["è²¡å¸›å®®"] = 10
    
    # å¤«å¦»å®®ï¼ˆ10åˆ†ï¼‰
    if extracted["å¤«å¦»å®®"]["found"] and "æ­¦æ›²" in extracted["å¤«å¦»å®®"]["content"]:
        scores["å¤«å¦»å®®"] = 10
    
    # æ€§æ ¼ï¼ˆ5åˆ†ï¼‰
    if extracted["æ€§æ ¼"]["found"]:
        keyword_count = len([k for k in GROUND_TRUTH["æ€§æ ¼ç‰¹è³ª"]["keywords"] 
                           if k in extracted["æ€§æ ¼"]["content"]])
        scores["æ€§æ ¼"] = min(5, keyword_count)
    
    # éŒ¯èª¤æ‰£åˆ†ï¼ˆæœ€å¤šæ‰£50åˆ†ï¼‰
    scores["éŒ¯èª¤æ‰£åˆ†"] = -min(50, len(extracted["éŒ¯èª¤æŒ‡æ¨™"]) * 25)
    
    total = sum(scores.values())
    total = max(0, total)  # ä¸ä½æ–¼0
    
    return total, scores

# ============================================
# ä¸»æ¸¬è©¦æµç¨‹
# ============================================

def run_single_test(iteration):
    """
    åŸ·è¡Œå–®æ¬¡æ¸¬è©¦
    """
    
    print(f"\n{'='*60}")
    print(f"[TEST] ç¬¬ {iteration + 1}/{TEST_ITERATIONS} æ¬¡æ¸¬è©¦")
    print(f"{'='*60}")
    
    try:
        # å»ºç«‹æ¨¡å‹
        model = genai.GenerativeModel(
            model_name=MODEL_NAME,
            system_instruction=SYSTEM_INSTRUCTION
        )
        
        # çµ„åˆæŸ¥è©¢
        user_prompt = USER_PROMPT_TEMPLATE.format(**BIRTH_INFO)
        
        # ç”Ÿæˆå›æ‡‰
        print("[API] æ­£åœ¨å‘¼å« API...")
        response = model.generate_content(
            user_prompt,
            generation_config=genai.GenerationConfig(
                temperature=TEMPERATURE,
                top_p=0.95,
                top_k=40
                # ç§»é™¤ max_output_tokens - æœƒå°è‡´ finish_reason=2 bug
            ),
            safety_settings=[
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
            ]
        )
        
        # æª¢æŸ¥å®‰å…¨éæ¿¾
        print(f"[DEBUG] prompt_feedback: {response.prompt_feedback}")
        
        if not response.candidates:
            print(f"[ERROR] ç„¡å€™é¸å›æ‡‰")
            raise Exception("å®‰å…¨éæ¿¾å™¨é˜»æ­¢äº†å›æ‡‰ç”Ÿæˆ")
        
        candidate = response.candidates[0]
        print(f"[DEBUG] finish_reason: {candidate.finish_reason}")
        print(f"[DEBUG] safety_ratings: {candidate.safety_ratings}")
        print(f"[DEBUG] content: {candidate.content if hasattr(candidate, 'content') else 'N/A'}")
        
        if candidate.finish_reason != 1:  # 1 = STOP (æ­£å¸¸å®Œæˆ)
            raise Exception(f"å›æ‡‰æœªæ­£å¸¸å®Œæˆï¼Œfinish_reason = {candidate.finish_reason}")
        
        result_text = response.text
        print(f"[OK] å›æ‡‰é•·åº¦ï¼š{len(result_text)} å­—")
        
        # æå–çµæ§‹
        extracted = extract_chart_structure(result_text)
        
        # è¨ˆç®—æº–ç¢ºåº¦
        accuracy, scores = calculate_accuracy(extracted)
        
        # é¡¯ç¤ºçµæœ
        print(f"\n[ANALYSIS] çµæ§‹åˆ†æï¼š")
        print(f"  å‘½å®®ï¼š{'[OK] ' if extracted['å‘½å®®']['found'] else '[X] '}{extracted['å‘½å®®']['content']}")
        print(f"  æ ¼å±€ï¼š{'[OK] ' if extracted['æ ¼å±€']['found'] else '[X] '}{extracted['æ ¼å±€']['content']}")
        print(f"  å®˜ç¥¿å®®ï¼š{'[OK] ' if extracted['å®˜ç¥¿å®®']['found'] else '[X] '}{extracted['å®˜ç¥¿å®®']['content']}")
        print(f"  è²¡å¸›å®®ï¼š{'[OK] ' if extracted['è²¡å¸›å®®']['found'] else '[X] '}{extracted['è²¡å¸›å®®']['content']}")
        print(f"  å¤«å¦»å®®ï¼š{'[OK] ' if extracted['å¤«å¦»å®®']['found'] else '[X] '}{extracted['å¤«å¦»å®®']['content']}")
        
        if extracted['éŒ¯èª¤æŒ‡æ¨™']:
            print(f"\n[WARNING] éŒ¯èª¤æŒ‡æ¨™ï¼š")
            for error in extracted['éŒ¯èª¤æŒ‡æ¨™']:
                print(f"    - {error}")
        
        print(f"\n[SCORE] æº–ç¢ºåº¦è©•åˆ†ï¼š{accuracy}/100")
        print(f"   è©³ç´°åˆ†æ•¸ï¼š{scores}")
        
        return {
            'iteration': iteration + 1,
            'success': True,
            'accuracy': accuracy,
            'scores': scores,
            'extracted': extracted,
            'full_text': result_text
        }
        
    except Exception as e:
        print(f"[ERROR] æ¸¬è©¦å¤±æ•—ï¼š{e}")
        return {
            'iteration': iteration + 1,
            'success': False,
            'error': str(e)
        }

def run_consistency_test():
    """
    åŸ·è¡Œå®Œæ•´ä¸€è‡´æ€§æ¸¬è©¦
    """
    
    print("\n" + "="*60)
    print(" Aetheria ä¸€è‡´æ€§æ¸¬è©¦")
    print("="*60)
    print(f"æ¸¬è©¦å°è±¡ï¼š{BIRTH_INFO['date']} {BIRTH_INFO['time']}")
    print(f"æ¸¬è©¦æ¬¡æ•¸ï¼š{TEST_ITERATIONS}")
    print(f"ä½¿ç”¨æ¨¡å‹ï¼š{MODEL_NAME}")
    print(f"æº«åº¦åƒæ•¸ï¼š{TEMPERATURE}")
    print("="*60)
    
    results = []
    
    # åŸ·è¡Œæ¸¬è©¦
    for i in range(TEST_ITERATIONS):
        result = run_single_test(i)
        results.append(result)
    
    # çµ±è¨ˆåˆ†æ
    print("\n\n" + "="*60)
    print("[STATS] çµ±è¨ˆåˆ†æ")
    print("="*60)
    
    successful_tests = [r for r in results if r['success']]
    failed_tests = [r for r in results if not r['success']]
    
    print(f"\næˆåŠŸæ¬¡æ•¸ï¼š{len(successful_tests)}/{TEST_ITERATIONS}")
    print(f"å¤±æ•—æ¬¡æ•¸ï¼š{len(failed_tests)}/{TEST_ITERATIONS}")
    
    if successful_tests:
        accuracies = [r['accuracy'] for r in successful_tests]
        avg_accuracy = sum(accuracies) / len(accuracies)
        min_accuracy = min(accuracies)
        max_accuracy = max(accuracies)
        
        print(f"\nğŸ“ˆ æº–ç¢ºåº¦çµ±è¨ˆï¼š")
        print(f"  å¹³å‡åˆ†æ•¸ï¼š{avg_accuracy:.1f}/100")
        print(f"  æœ€é«˜åˆ†æ•¸ï¼š{max_accuracy}/100")
        print(f"  æœ€ä½åˆ†æ•¸ï¼š{min_accuracy}/100")
        print(f"  æ¨™æº–å·®ï¼š{calculate_std_dev(accuracies):.1f}")
        
        # ä¸€è‡´æ€§åˆ¤å®š
        print(f"\nğŸ¯ ä¸€è‡´æ€§è©•ä¼°ï¼š")
        
        if avg_accuracy >= 90:
            consistency = "éå¸¸é«˜ [OK]"
            recommendation = "LLM éå¸¸å¯é ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨é¸é … Aï¼ˆç´” LLM å®šç›¤ï¼‰"
        elif avg_accuracy >= 70:
            consistency = "ä¸­ç­‰ âš ï¸"
            recommendation = "LLM éƒ¨åˆ†å¯é ï¼Œå»ºè­°é¸é … A + ç¢ºå®šæ€§é©—è­‰ï¼ˆæ··åˆæ–¹æ¡ˆï¼‰"
        else:
            consistency = "ä½ âŒ"
            recommendation = "LLM ä¸å¤ å¯é ï¼Œå»ºè­°ä½¿ç”¨ç¢ºå®šæ€§ç³»çµ±æ’ç›¤ + LLM è©®é‡‹"
        
        print(f"  ä¸€è‡´æ€§ç­‰ç´šï¼š{consistency}")
        print(f"  å»ºè­°æ–¹æ¡ˆï¼š{recommendation}")
        
        # å…·é«”å•é¡Œåˆ†æ
        print(f"\nğŸ” è©³ç´°åˆ†æï¼š")
        
        # çµ±è¨ˆå„é …çš„æ­£ç¢ºç‡
        fields = ["å‘½å®®", "æ ¼å±€", "å®˜ç¥¿å®®", "è²¡å¸›å®®", "å¤«å¦»å®®"]
        for field in fields:
            correct_count = sum(1 for r in successful_tests if r['extracted'][field]['found'])
            rate = correct_count / len(successful_tests) * 100
            status = "âœ…" if rate >= 80 else "âš ï¸" if rate >= 50 else "âŒ"
            print(f"  {field}ï¼š{status} {rate:.0f}% ({correct_count}/{len(successful_tests)})")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åš´é‡éŒ¯èª¤
        error_count = sum(1 for r in successful_tests if r['extracted']['éŒ¯èª¤æŒ‡æ¨™'])
        if error_count > 0:
            print(f"\nâš ï¸  è­¦å‘Šï¼š{error_count}/{len(successful_tests)} æ¬¡å‡ºç¾åš´é‡éŒ¯èª¤ï¼ˆå¦‚å‘½å®®éŒ¯èª¤ï¼‰")
    
    # å„²å­˜çµæœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"consistency_test_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump({
            'test_info': {
                'birth_info': BIRTH_INFO,
                'model': MODEL_NAME,
                'temperature': TEMPERATURE,
                'iterations': TEST_ITERATIONS,
                'timestamp': timestamp
            },
            'ground_truth': GROUND_TRUTH,
            'results': results,
            'statistics': {
                'avg_accuracy': avg_accuracy if successful_tests else 0,
                'consistency_level': consistency if successful_tests else "æœªçŸ¥"
            }
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ å®Œæ•´çµæœå·²å„²å­˜åˆ°ï¼š{filename}")
    
    # ç”Ÿæˆå ±å‘Š
    generate_report(results, filename)
    
    return results

def calculate_std_dev(numbers):
    """è¨ˆç®—æ¨™æº–å·®"""
    if not numbers:
        return 0
    mean = sum(numbers) / len(numbers)
    variance = sum((x - mean) ** 2 for x in numbers) / len(numbers)
    return variance ** 0.5

def generate_report(results, json_filename):
    """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_filename = f"consistency_report_{timestamp}.txt"
    
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write("="*60 + "\n")
        f.write("Aetheria ä¸€è‡´æ€§æ¸¬è©¦å ±å‘Š\n")
        f.write("="*60 + "\n\n")
        
        f.write(f"æ¸¬è©¦æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ¸¬è©¦å°è±¡ï¼š{BIRTH_INFO['date']} {BIRTH_INFO['time']} {BIRTH_INFO['location']} {BIRTH_INFO['gender']}\n")
        f.write(f"æ¸¬è©¦æ¬¡æ•¸ï¼š{TEST_ITERATIONS}\n")
        f.write(f"ä½¿ç”¨æ¨¡å‹ï¼š{MODEL_NAME}\n")
        f.write(f"æº«åº¦åƒæ•¸ï¼š{TEMPERATURE}\n\n")
        
        successful = [r for r in results if r['success']]
        
        if successful:
            accuracies = [r['accuracy'] for r in successful]
            avg = sum(accuracies) / len(accuracies)
            
            f.write("="*60 + "\n")
            f.write("çµ±è¨ˆçµæœ\n")
            f.write("="*60 + "\n\n")
            f.write(f"å¹³å‡æº–ç¢ºåº¦ï¼š{avg:.1f}/100\n")
            f.write(f"æœ€é«˜åˆ†æ•¸ï¼š{max(accuracies)}/100\n")
            f.write(f"æœ€ä½åˆ†æ•¸ï¼š{min(accuracies)}/100\n")
            f.write(f"æ¨™æº–å·®ï¼š{calculate_std_dev(accuracies):.1f}\n\n")
            
            f.write("="*60 + "\n")
            f.write("æ¯æ¬¡æ¸¬è©¦è©³æƒ…\n")
            f.write("="*60 + "\n\n")
            
            for r in successful:
                f.write(f"ç¬¬ {r['iteration']} æ¬¡æ¸¬è©¦ï¼š{r['accuracy']}/100\n")
                f.write(f"  å‘½å®®ï¼š{r['extracted']['å‘½å®®']['content']}\n")
                f.write(f"  æ ¼å±€ï¼š{r['extracted']['æ ¼å±€']['content']}\n")
                if r['extracted']['éŒ¯èª¤æŒ‡æ¨™']:
                    f.write(f"  éŒ¯èª¤ï¼š{', '.join(r['extracted']['éŒ¯èª¤æŒ‡æ¨™'])}\n")
                f.write("\n")
        
        f.write(f"\nå®Œæ•´æ•¸æ“šè«‹æŸ¥çœ‹ï¼š{json_filename}\n")
    
    print(f"[SAVE] æ¸¬è©¦å ±å‘Šå·²å„²å­˜åˆ°ï¼š{report_filename}")

# ============================================
# ä¸»ç¨‹å¼å…¥å£
# ============================================

if __name__ == "__main__":
    run_consistency_test()
