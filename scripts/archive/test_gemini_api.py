"""
Gemini API ç¨ç«‹æ¸¬è©¦è…³æœ¬
æ¸¬è©¦ Gemini 2.0 Flash API çš„åŸºæœ¬åŠŸèƒ½å’Œ streaming æ˜¯å¦æ­£å¸¸
"""
import os
import sys
import time
from datetime import datetime
from dotenv import load_dotenv

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# è¼‰å…¥ .env æª”æ¡ˆ
load_dotenv()

try:
    import google.generativeai as genai
    from google.generativeai import types
    print("âœ… google.generativeai å°å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å°å…¥å¤±æ•—: {e}")
    sys.exit(1)

def test_gemini_api():
    """æ¸¬è©¦ Gemini API åŸºæœ¬åŠŸèƒ½"""
    
    # ç²å– API Key
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ ç’°å¢ƒè®Šæ•¸ GEMINI_API_KEY æœªè¨­ç½®")
        return False
    
    print(f"âœ… API Key å·²æ‰¾åˆ° (é•·åº¦: {len(api_key)})")
    
    try:
        # é…ç½® API
        genai.configure(api_key=api_key)
        print("âœ… Gemini API é…ç½®æˆåŠŸ")
        
        # å‰µå»ºæ¨¡å‹
        model = genai.GenerativeModel('gemini-3-flash-preview')
        print("âœ… æ¨¡å‹å‰µå»ºæˆåŠŸ: gemini-3-flash-preview")
        
        # æ¸¬è©¦ 1: é streaming è«‹æ±‚
        print("\n" + "="*60)
        print("æ¸¬è©¦ 1: é Streaming è«‹æ±‚")
        print("="*60)
        
        start_time = time.time()
        prompt = "è«‹ç”¨ä¸€å¥è©±å›ç­”ï¼š2+2ç­‰æ–¼å¤šå°‘ï¼Ÿ"
        print(f"ğŸ“¤ ç™¼é€è«‹æ±‚: {prompt}")
        
        response = model.generate_content(prompt)
        elapsed = time.time() - start_time
        
        print(f"âœ… æ”¶åˆ°å›æ‡‰ (è€—æ™‚: {elapsed:.2f}ç§’)")
        print(f"ğŸ“¥ å›æ‡‰å…§å®¹: {response.text}")
        
        # æ¸¬è©¦ 2: Streaming è«‹æ±‚
        print("\n" + "="*60)
        print("æ¸¬è©¦ 2: Streaming è«‹æ±‚")
        print("="*60)
        
        start_time = time.time()
        prompt = "è«‹ç”¨30å­—ä»¥å…§ä»‹ç´¹å…«å­—å‘½ç†"
        print(f"ğŸ“¤ ç™¼é€ streaming è«‹æ±‚: {prompt}")
        
        response_stream = model.generate_content(prompt, stream=True)
        
        chunks_received = 0
        full_text = ""
        first_chunk_time = None
        
        print("ğŸ“¥ æ¥æ”¶ streaming chunks:")
        for chunk in response_stream:
            if first_chunk_time is None:
                first_chunk_time = time.time() - start_time
                print(f"   â±ï¸ é¦–å€‹ chunk è€—æ™‚: {first_chunk_time:.2f}ç§’")
            
            chunks_received += 1
            if hasattr(chunk, 'text'):
                chunk_text = chunk.text
                full_text += chunk_text
                print(f"   Chunk {chunks_received}: {len(chunk_text)} å­—å…ƒ")
        
        elapsed = time.time() - start_time
        print(f"âœ… Streaming å®Œæˆ")
        print(f"   ç¸½ chunks: {chunks_received}")
        print(f"   ç¸½è€—æ™‚: {elapsed:.2f}ç§’")
        print(f"   å®Œæ•´å…§å®¹: {full_text}")
        
        # æ¸¬è©¦ 3: è¼ƒé•·çš„ streaming è«‹æ±‚ï¼ˆæ¨¡æ“¬å¯¦éš›å ´æ™¯ï¼‰
        print("\n" + "="*60)
        print("æ¸¬è©¦ 3: è¼ƒé•· Streaming è«‹æ±‚ï¼ˆæ¨¡æ“¬å‘½ç†è«®è©¢ï¼‰")
        print("="*60)
        
        start_time = time.time()
        prompt = """è«‹ä½ æ‰®æ¼”ä¸€ä½å‘½ç†è€å¸«ï¼Œç°¡çŸ­å›ç­”ä»¥ä¸‹å•é¡Œï¼š
        
ç”¨æˆ¶èªªï¼šæˆ‘1990å¹´5æœˆ15æ—¥æ—©ä¸Š8é»å‡ºç”Ÿï¼Œæƒ³äº†è§£æˆ‘çš„äº‹æ¥­é‹å‹¢ã€‚

è«‹ç”¨80å­—ä»¥å…§çµ¦å‡ºå°ˆæ¥­å›æ‡‰ã€‚"""
        
        print(f"ğŸ“¤ ç™¼é€è¤‡é›œ streaming è«‹æ±‚")
        
        response_stream = model.generate_content(prompt, stream=True)
        
        chunks_received = 0
        full_text = ""
        first_chunk_time = None
        timeout_seconds = 30
        
        print("ğŸ“¥ æ¥æ”¶ streaming chunks (30ç§’è¶…æ™‚):")
        
        try:
            for chunk in response_stream:
                if first_chunk_time is None:
                    first_chunk_time = time.time() - start_time
                    print(f"   â±ï¸ é¦–å€‹ chunk è€—æ™‚: {first_chunk_time:.2f}ç§’")
                
                chunks_received += 1
                if hasattr(chunk, 'text'):
                    chunk_text = chunk.text
                    full_text += chunk_text
                    print(f"   Chunk {chunks_received}: {len(chunk_text)} å­—å…ƒ")
                
                # è¶…æ™‚æª¢æŸ¥
                if time.time() - start_time > timeout_seconds:
                    print(f"âš ï¸ è¶…é {timeout_seconds} ç§’ï¼Œä¸­æ–·æ¸¬è©¦")
                    break
            
            elapsed = time.time() - start_time
            
            if chunks_received > 0:
                print(f"âœ… Streaming å®Œæˆ")
                print(f"   ç¸½ chunks: {chunks_received}")
                print(f"   ç¸½è€—æ™‚: {elapsed:.2f}ç§’")
                print(f"   å®Œæ•´å…§å®¹: {full_text[:200]}...")
            else:
                print(f"âŒ æ²’æœ‰æ”¶åˆ°ä»»ä½• chunk (ç­‰å¾…äº† {elapsed:.2f}ç§’)")
                return False
                
        except Exception as e:
            print(f"âŒ Streaming éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼Gemini API å·¥ä½œæ­£å¸¸")
        print("="*60)
        return True
        
    except Exception as e:
        print(f"\nâŒ API æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("="*60)
    print("Gemini API ç¨ç«‹æ¸¬è©¦")
    print(f"æ¸¬è©¦æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    success = test_gemini_api()
    
    if success:
        print("\nğŸ‰ çµè«–: Gemini API å·¥ä½œæ­£å¸¸ï¼Œå•é¡Œå¯èƒ½åœ¨å…¶ä»–åœ°æ–¹")
        sys.exit(0)
    else:
        print("\nâš ï¸ çµè«–: Gemini API å­˜åœ¨å•é¡Œï¼Œéœ€è¦é€²ä¸€æ­¥æ’æŸ¥")
        sys.exit(1)
